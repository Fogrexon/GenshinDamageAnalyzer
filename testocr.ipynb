{"cells":[{"cell_type":"markdown","metadata":{},"source":["\n","**Project Repository:** https://github.com/GokulKarthik/deep-learning-projects-pytorch"]},{"cell_type":"markdown","metadata":{},"source":["### References:\n","[1] https://github.com/carnotaur/crnn-tutorial/"]},{"cell_type":"code","execution_count":6,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import os\n","import glob\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from torchvision.models import resnet18\n","\n","import string\n","from tqdm.notebook import tqdm\n","import cv2\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import multiprocessing as mp"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["16\n"]}],"source":["cpu_count = mp.cpu_count()\n","print(cpu_count)"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Make train-test split"]},{"cell_type":"markdown","metadata":{},"source":["**Data Link**: https://www.kaggle.com/shawon10/captcha-recognition"]},{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["data_path = \"/samples\""]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[WinError 3] 指定されたパスが見つかりません。: '/kaggle/input/captcha-version-2-images/samples'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\ka244\\Anaconda\\genshin\\testocr.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ka244/Anaconda/genshin/testocr.ipynb#ch0000007?line=0'>1</a>\u001b[0m image_fns \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(data_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ka244/Anaconda/genshin/testocr.ipynb#ch0000007?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(image_fns))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ka244/Anaconda/genshin/testocr.ipynb#ch0000007?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39munique([\u001b[39mlen\u001b[39m(image_fn\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m image_fn \u001b[39min\u001b[39;00m image_fns]))\n","\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 指定されたパスが見つかりません。: '/kaggle/input/captcha-version-2-images/samples'"]}],"source":["image_fns = os.listdir(data_path)\n","print(len(image_fns))\n","print(np.unique([len(image_fn.split(\".\")[0]) for image_fn in image_fns]))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for idx, image_fn in enumerate(image_fns):\n","    if len(image_fn.split(\".\")[0]) != 5:\n","           print(idx, image_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["image_fns.remove('samples')\n","print(len(image_fns))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["image_fns_train, image_fns_test = train_test_split(image_fns, random_state=0)\n","print(len(image_fns_train), len(image_fns_test))"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Define character maps"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["image_ns = [image_fn.split(\".\")[0] for image_fn in image_fns]\n","image_ns = \"\".join(image_ns)\n","letters = sorted(list(set(list(image_ns))))\n","print(len(letters))\n","print(letters)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["vocabulary = [\"-\"] + letters\n","print(len(vocabulary))\n","print(vocabulary)\n","idx2char = {k:v for k,v in enumerate(vocabulary, start=0)}\n","print(idx2char)\n","char2idx = {v:k for k,v in idx2char.items()}\n","print(char2idx)"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Define data loader"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["batch_size = 16"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class CAPTCHADataset(Dataset):\n","    \n","    def __init__(self, data_dir, image_fns):\n","        self.data_dir = data_dir\n","        self.image_fns = image_fns\n","        \n","    def __len__(self):\n","        return len(self.image_fns)\n","    \n","    def __getitem__(self, index):\n","        image_fn = self.image_fns[index]\n","        image_fp = os.path.join(self.data_dir, image_fn)\n","        image = Image.open(image_fp).convert('RGB')\n","        image = self.transform(image)\n","        text = image_fn.split(\".\")[0]\n","        return image, text\n","    \n","    def transform(self, image):\n","        \n","        transform_ops = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n","        ])\n","        return transform_ops(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trainset = CAPTCHADataset(data_path, image_fns_train) \n","testset = CAPTCHADataset(data_path, image_fns_test)\n","train_loader = DataLoader(trainset, batch_size=batch_size, num_workers=cpu_count, shuffle=True)\n","test_loader = DataLoader(testset, batch_size=batch_size, num_workers=cpu_count, shuffle=False)\n","print(len(train_loader), len(test_loader))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["image_batch, text_batch = iter(train_loader).next()\n","print(image_batch.size(), text_batch)"]},{"cell_type":"markdown","metadata":{},"source":["## 4. Define model"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'char2idx' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\ka244\\Anaconda\\genshin\\testocr.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ka244/Anaconda/genshin/testocr.ipynb#ch0000020?line=0'>1</a>\u001b[0m num_chars \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(char2idx)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ka244/Anaconda/genshin/testocr.ipynb#ch0000020?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(num_chars)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ka244/Anaconda/genshin/testocr.ipynb#ch0000020?line=2'>3</a>\u001b[0m rnn_hidden_size \u001b[39m=\u001b[39m \u001b[39m256\u001b[39m\n","\u001b[1;31mNameError\u001b[0m: name 'char2idx' is not defined"]}],"source":["num_chars = len(char2idx)\n","print(num_chars)\n","rnn_hidden_size = 256"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["resnet = resnet18(pretrained=True)\n","#print(resnet)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class CRNN(nn.Module):\n","    \n","    def __init__(self, num_chars, rnn_hidden_size=256, dropout=0.1):\n","        \n","        super(CRNN, self).__init__()\n","        self.num_chars = num_chars\n","        self.rnn_hidden_size = rnn_hidden_size\n","        self.dropout = dropout\n","        \n","        # CNN Part 1\n","        resnet_modules = list(resnet.children())[:-3]\n","        self.cnn_p1 = nn.Sequential(*resnet_modules)\n","        \n","        # CNN Part 2\n","        self.cnn_p2 = nn.Sequential(\n","            nn.Conv2d(256, 256, kernel_size=(3,6), stride=1, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(inplace=True)\n","        )\n","        self.linear1 = nn.Linear(1024, 256)\n","        \n","        # RNN\n","        self.rnn1 = nn.GRU(input_size=rnn_hidden_size, \n","                            hidden_size=rnn_hidden_size,\n","                            bidirectional=True, \n","                            batch_first=True)\n","        self.rnn2 = nn.GRU(input_size=rnn_hidden_size, \n","                            hidden_size=rnn_hidden_size,\n","                            bidirectional=True, \n","                            batch_first=True)\n","        self.linear2 = nn.Linear(self.rnn_hidden_size*2, num_chars)\n","        \n","        \n","    def forward(self, batch):\n","        \n","        batch = self.cnn_p1(batch)\n","        # print(batch.size()) # torch.Size([-1, 256, 4, 13])\n","        \n","        batch = self.cnn_p2(batch) # [batch_size, channels, height, width]\n","        # print(batch.size())# torch.Size([-1, 256, 4, 10])\n","        \n","        batch = batch.permute(0, 3, 1, 2) # [batch_size, width, channels, height]\n","        # print(batch.size()) # torch.Size([-1, 10, 256, 4])\n","         \n","        batch_size = batch.size(0)\n","        T = batch.size(1)\n","        batch = batch.view(batch_size, T, -1) # [batch_size, T==width, num_features==channels*height]\n","        # print(batch.size()) # torch.Size([-1, 10, 1024])\n","        \n","        batch = self.linear1(batch)\n","        # print(batch.size()) # torch.Size([-1, 10, 256])\n","        \n","        batch, hidden = self.rnn1(batch)\n","        feature_size = batch.size(2)\n","        batch = batch[:, :, :feature_size//2] + batch[:, :, feature_size//2:]\n","        # print(batch.size()) # torch.Size([-1, 10, 256])\n","        \n","        batch, hidden = self.rnn2(batch)\n","        # print(batch.size()) # torch.Size([-1, 10, 512])\n","        \n","        batch = self.linear2(batch)\n","        # print(batch.size()) # torch.Size([-1, 10, 20])\n","        \n","        batch = batch.permute(1, 0, 2) # [T==10, batch_size, num_classes==num_features]\n","        # print(batch.size()) # torch.Size([10, -1, 20])\n","        \n","        return batch"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def weights_init(m):\n","    classname = m.__class__.__name__\n","    if type(m) in [nn.Linear, nn.Conv2d, nn.Conv1d]:\n","        torch.nn.init.xavier_uniform_(m.weight)\n","        if m.bias is not None:\n","            m.bias.data.fill_(0.01)\n","    elif classname.find('BatchNorm') != -1:\n","        m.weight.data.normal_(1.0, 0.02)\n","        m.bias.data.fill_(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["crnn = CRNN(num_chars, rnn_hidden_size=rnn_hidden_size)\n","crnn.apply(weights_init)\n","crnn = crnn.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#crnn"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["text_batch_logits = crnn(image_batch.to(device))\n","print(text_batch)\n","print(text_batch_logits.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## 5. Define loss"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["criterion = nn.CTCLoss(blank=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def encode_text_batch(text_batch):\n","    \n","    text_batch_targets_lens = [len(text) for text in text_batch]\n","    text_batch_targets_lens = torch.IntTensor(text_batch_targets_lens)\n","    \n","    text_batch_concat = \"\".join(text_batch)\n","    text_batch_targets = [char2idx[c] for c in text_batch_concat]\n","    text_batch_targets = torch.IntTensor(text_batch_targets)\n","    \n","    return text_batch_targets, text_batch_targets_lens"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def compute_loss(text_batch, text_batch_logits):\n","    \"\"\"\n","    text_batch: list of strings of length equal to batch size\n","    text_batch_logits: Tensor of size([T, batch_size, num_classes])\n","    \"\"\"\n","    text_batch_logps = F.log_softmax(text_batch_logits, 2) # [T, batch_size, num_classes]  \n","    text_batch_logps_lens = torch.full(size=(text_batch_logps.size(1),), \n","                                       fill_value=text_batch_logps.size(0), \n","                                       dtype=torch.int32).to(device) # [batch_size] \n","    #print(text_batch_logps.shape)\n","    #print(text_batch_logps_lens) \n","    text_batch_targets, text_batch_targets_lens = encode_text_batch(text_batch)\n","    #print(text_batch_targets)\n","    #print(text_batch_targets_lens)\n","    loss = criterion(text_batch_logps, text_batch_targets, text_batch_logps_lens, text_batch_targets_lens)\n","\n","    return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["compute_loss(text_batch, text_batch_logits)"]},{"cell_type":"markdown","metadata":{},"source":["## 6. Train model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["num_epochs = 50\n","lr = 0.001\n","weight_decay = 1e-3\n","clip_norm = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["optimizer = optim.Adam(crnn.parameters(), lr=lr, weight_decay=weight_decay)\n","lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["crnn = CRNN(num_chars, rnn_hidden_size=rnn_hidden_size)\n","crnn.apply(weights_init)\n","crnn = crnn.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["epoch_losses = []\n","iteration_losses = []\n","num_updates_epochs = []\n","for epoch in tqdm(range(1, num_epochs+1)):\n","    epoch_loss_list = [] \n","    num_updates_epoch = 0\n","    for image_batch, text_batch in tqdm(train_loader, leave=False):\n","        optimizer.zero_grad()\n","        text_batch_logits = crnn(image_batch.to(device))\n","        loss = compute_loss(text_batch, text_batch_logits)\n","        iteration_loss = loss.item()\n","\n","        if np.isnan(iteration_loss) or np.isinf(iteration_loss):\n","            continue\n","          \n","        num_updates_epoch += 1\n","        iteration_losses.append(iteration_loss)\n","        epoch_loss_list.append(iteration_loss)\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(crnn.parameters(), clip_norm)\n","        optimizer.step()\n","\n","    epoch_loss = np.mean(epoch_loss_list)\n","    print(\"Epoch:{}    Loss:{}    NumUpdates:{}\".format(epoch, epoch_loss, num_updates_epoch))\n","    epoch_losses.append(epoch_loss)\n","    num_updates_epochs.append(num_updates_epoch)\n","    lr_scheduler.step(epoch_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n","\n","ax1.plot(epoch_losses)\n","ax1.set_xlabel(\"Epochs\")\n","ax1.set_ylabel(\"Loss\")\n","\n","ax2.plot(iteration_losses)\n","ax2.set_xlabel(\"Iterations\")\n","ax2.set_ylabel(\"Loss\")\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## 7. Make predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def decode_predictions(text_batch_logits):\n","\n","    text_batch_tokens = F.softmax(text_batch_logits, 2).argmax(2) # [T, batch_size]\n","    text_batch_tokens = text_batch_tokens.numpy().T # [batch_size, T]\n","\n","    text_batch_tokens_new = []\n","    for text_tokens in text_batch_tokens:\n","        text = [idx2char[idx] for idx in text_tokens]\n","        text = \"\".join(text)\n","        text_batch_tokens_new.append(text)\n","\n","    return text_batch_tokens_new"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["results_train = pd.DataFrame(columns=['actual', 'prediction'])\n","train_loader = DataLoader(trainset, batch_size=16, num_workers=1, shuffle=False)\n","with torch.no_grad():\n","    for image_batch, text_batch in tqdm(train_loader, leave=True):\n","        text_batch_logits = crnn(image_batch.to(device)) # [T, batch_size, num_classes==num_features]\n","        text_batch_pred = decode_predictions(text_batch_logits.cpu())\n","        #print(text_batch, text_batch_pred)\n","        df = pd.DataFrame(columns=['actual', 'prediction'])\n","        df['actual'] = text_batch\n","        df['prediction'] = text_batch_pred\n","        results_train = pd.concat([results_train, df])\n","results_train = results_train.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["results_test = pd.DataFrame(columns=['actual', 'prediction'])\n","test_loader = DataLoader(testset, batch_size=16, num_workers=1, shuffle=False)\n","with torch.no_grad():\n","    for image_batch, text_batch in tqdm(test_loader, leave=True):\n","        text_batch_logits = crnn(image_batch.to(device)) # [T, batch_size, num_classes==num_features]\n","        text_batch_pred = decode_predictions(text_batch_logits.cpu())\n","        #print(text_batch, text_batch_pred)\n","        df = pd.DataFrame(columns=['actual', 'prediction'])\n","        df['actual'] = text_batch\n","        df['prediction'] = text_batch_pred\n","        results_test = pd.concat([results_test, df])\n","results_test = results_test.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(results_train.shape)\n","results_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(results_test.shape)\n","results_test.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def remove_duplicates(text):\n","    if len(text) > 1:\n","        letters = [text[0]] + [letter for idx, letter in enumerate(text[1:], start=1) if text[idx] != text[idx-1]]\n","    elif len(text) == 1:\n","        letters = [text[0]]\n","    else:\n","        return \"\"\n","    return \"\".join(letters)\n","\n","def correct_prediction(word):\n","    parts = word.split(\"-\")\n","    parts = [remove_duplicates(part) for part in parts]\n","    corrected_word = \"\".join(parts)\n","    return corrected_word"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["results_train['prediction_corrected'] = results_train['prediction'].apply(correct_prediction)\n","results_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["results_test['prediction_corrected'] = results_test['prediction'].apply(correct_prediction)\n","results_test.head()"]},{"cell_type":"markdown","metadata":{},"source":["## 8. Evaluate the model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mistakes_df = results_test[results_test['actual'] != results_test['prediction_corrected']]\n","mistakes_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(mistakes_df['prediction_corrected'].str.len().value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mask = mistakes_df['prediction_corrected'].str.len() == 5\n","mistakes_df[mask]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mistake_image_fp = os.path.join(data_path, mistakes_df[mask]['actual'].values[0] + \".png\")\n","print(mistake_image_fp)\n","mistake_image = Image.open(mistake_image_fp)\n","plt.imshow(mistake_image)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_accuracy = accuracy_score(results_train['actual'], results_train['prediction_corrected'])\n","print(train_accuracy)\n","test_accuracy = accuracy_score(results_test['actual'], results_test['prediction_corrected'])\n","print(test_accuracy)"]}],"metadata":{"kernelspec":{"display_name":"opencv","language":"python","name":"opencv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":1}
